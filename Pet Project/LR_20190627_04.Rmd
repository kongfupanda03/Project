---
title: "LR_20190627_04"
author: "Yuyu"
date: "June 24, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

```{r remove historical objects}
rm(list=ls())
```

```{r 0. library, include=FALSE}
library(tidyverse)
library(plotly)
library(ggcorrplot)
library(Metrics)
library(fastDummies)
library(ggthemes)
library(zoo)
library(GGally)
```

```{r 1. load dataset}
ames <- read.csv("house_price_train.csv")
```

```{r 2. Data Quality Check (i)}
## Check the whole data set
names(ames)
ds <- ames

## Check missing values in each column
ds %>% 
  glimpse(.) %>% 
  apply(.,2,function(x)sum(is.na(x)))

##==================================================##
## There are only 2 types of data in this dataset, which are integer and factor variables
##
## Looking through the data, we find that there are large amount of missing valuse in columns like PoolQC, Fence, MiscFeature
##==================================================##

```

```{r 2. Data Quality Check (ii) -- Factor columns}
## Check factor columns
ds$Id <- as.factor(ds$Id)
ds_f <- ds %>% select_if(is.factor)

## Check missing values in factor columns
ds_f %>%
  apply(.,2,function(x)sum(is.na(x)))

levels(ds_f$MiscFeature)
## "Gar2" "Othr" "Shed" "TenC"

##==================================================##
## Go back to raw data, we can find that: 
## MiscFeature: Miscellaneous feature not covered in other categories
##  Elev	Elevator
##  Gar2	2nd Garage (if not described in garage section)
##  Othr	Other
##  Shed	Shed (over 100 SF)
##  TenC	Tennis Court
##  NA	  None *****
##
## Conclusion: R has automatically processd "NA" charactor as NA value
##==================================================##

## Record the columns with "NA" level manually as below:
## Alley, BsmtQual, BsmtCond, BsmtExposure, BsmtFinType1, BsmtFinType2, FireplaceQu, GarageType, GarageFinish, GarageQual, GarageCond, PoolQC, Fence, MiscFeature

## Change the data type of these columns into charactor
temp <- ds_f %>% 
  select(c(Alley, BsmtQual, BsmtCond, 
           BsmtExposure, BsmtFinType1, 
           BsmtFinType2, FireplaceQu, 
           GarageType, GarageFinish, 
           GarageQual, GarageCond, PoolQC, 
           Fence, MiscFeature)) %>% 
  mutate_all(as.character)

## Modify "NA" to "None"
temp[is.na(temp)] <- "None"

ds_f <- ds_f %>%
  select(-c(Alley, BsmtQual, BsmtCond, 
           BsmtExposure, BsmtFinType1, 
           BsmtFinType2, FireplaceQu, 
           GarageType, GarageFinish, 
           GarageQual, GarageCond, PoolQC, 
           Fence, MiscFeature)) %>%
  cbind(.,temp) %>%
  mutate_all(as.factor)

ds_f$Id <- as.integer(ds$Id)

```

```{r 2. Data Quality Check (iii) -- Integer columns}
## Check factor columns
ds$Id <- as.integer(ds$Id)
ds_i <- ds %>% 
  select_if(is.integer)

## Check missing values in integer columns
ds_i %>% 
  apply(.,2,function(x)sum(is.na(x)))

## Exclude column LotFrontage with 259 missing values
ds_i <- ds_i %>% 
  select(-c(LotFrontage))

```

```{r 2. Data Quality Check (iv) -- Combined Columns}
## Check combined columns
ds1 <- cbind(ds_i, ds_f %>% select(-c(Id)))
ds1 %>% 
  apply(.,2,function(x)sum(is.na(x)))

## Exclude rows with missing values
ds2 <- ds1 %>%
  filter(is.na(MasVnrArea) == FALSE, 
         is.na(GarageYrBlt) == FALSE, 
         is.na(MasVnrType) == FALSE,
         is.na(Electrical) == FALSE)

which(is.na(ds2), arr.ind=TRUE)
##     row col

## Thus, we get a clean dataset without missing values.
```

```{r 2. Data Quality Check (v) -- data type double check}
glimpse(ds2)

## By going through the raw dataset again, we find the following variables are assigned incorrect type.
## MSSubClass, MoSold, YrSold

## For column "MSSubClass", need to change to factor
## For columns "MoSold" & "YrSold", need to do combination and transform into timestamp format

## There are also some columns indicating "year", like "YearBuilt" and "YearRemodAdd", I will transform these columns to year diffenence (from 2019)

```

```{r 3. Data Transformation (i)}
## Transform columns which represent years to year diffenence from 2019
current_yr <- 2019
ds2$YearBuilt <- current_yr - ds2$YearBuilt
ds2$YearRemodAdd <- current_yr - ds2$YearRemodAdd
ds2$GarageYrBlt <- current_yr - ds2$GarageYrBlt

## Change an integer column MSSubClass into factor
ds2$MSSubClass <- as.factor(ds2$MSSubClass)
```

```{r 3. Data Transformation (ii)}
## Add SaleDate time stamp and reform SalePrice in 10000
ds2 <- ds2 %>%
  mutate(SaleDate = 
           as.POSIXct(as.yearmon(paste(YrSold, MoSold), "%Y %m"))) %>%
  mutate(Sale_Price=SalePrice/10000) %>%
  select(-c(SalePrice)) 
```

```{r 4. Data Exploration (i)}
## Do Histogram to original numeric columns
hist <- ds2 %>% 
  select(c(3:34)) %>%
  gather() 

ggplotly(ggplot(hist, aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_histogram() +
  stat_count(width = 0.5) +
  theme_tufte())

```

```{r 4. Data Exploration (ii), warning=FALSE}
## Create quantiles for Sale_Price
bins <- c(-Inf, 3.5311, 13.3900, 16.7000, 21.8000, 34.2643, Inf)
lbs <- c("A", "B", "C", "D", "E", "F")
ds2$Sale_Price_Bins <- cut(ds2$Sale_Price, breaks = bins, labels = lbs)
bins_cnt <- data.frame(ds2 %>% 
                         group_by(Sale_Price_Bins) %>%
                         summarise(count=n()))
plot_ly(bins_cnt, 
        x=bins_cnt[,1], 
        y=bins_cnt[,2], 
        type = "bar")

## Do scatter plot to original numeric columns
scatter_n <- ds2 %>% 
  select(-c(Id)) %>%
  select_if(is.integer)

ggpairs(scatter_n, columns = 1:7) +
  theme_tufte()
ggpairs(scatter_n, columns = 8:14) +
  theme_tufte()
ggpairs(scatter_n, columns = 15:21) +
  theme_tufte()
ggpairs(scatter_n, columns = 22:29)+
  theme_tufte()
```

```{r 4. Data Exploration (iii)}
## Do Histogram to first group of factor columns
bar_f_1 <- ds2 %>% select_if(is.factor) %>%
  select(c(1:16)) %>%
  mutate_all(as.character) %>%
  gather()
ggplotly(ggplot(bar_f_1, aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_bar() +
  theme_tufte())

bar_f_2 <- ds2 %>% select_if(is.factor) %>%
  select(c(17:32)) %>%
  mutate_all(as.character) %>%
  gather()
ggplotly(ggplot(bar_f_2, aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_bar() +
  theme_tufte())

bar_f_3 <- ds2 %>% select_if(is.factor) %>%
  select(c(33:44)) %>%
  mutate_all(as.character) %>%
  gather()
ggplotly(ggplot(bar_f_3, aes(value)) +
  facet_wrap(~ key, scales = "free") +
  geom_bar() +
  theme_tufte())

```

```{r 4. Data Exploration (iv)}
## Exclude some columns with great bias in a certain level
ds3 <- ds2 %>% 
  select(-c(PoolQC, MiscFeature, GarageQual, GarageCond,
            BsmtCond, PavedDrive, Heating, Functional,
            ExterCond, Electrical, CentralAir, Alley,
            Condition2, LandContour, LandSlope, RoofMatl,
            Street, Utilities)) %>% 
  dummy_cols(., remove_first_dummy = TRUE)

## Consistent numeric data type
ds4 <- ds3 %>% 
  select(-c("Id", "MoSold", "YrSold")) %>%
  select_if(negate(is.factor)) %>% 
  mutate_all(as.numeric)

## Calculate correlations of sale price with other features
crl <- data.frame(cor(ds4 %>% select(-c("Sale_Price")), ds4$Sale_Price)) %>% mutate(feature = row.names(.))
names(crl)[1] <- "correlation"
rownames(crl) <- NULL

## Check positive and negative ones, whose correlation should be greater than 0.5, notice that there is no criteria for this, you can also keep all features in your model to try.
strong_crl <- crl %>% arrange(desc(correlation)) %>% filter(correlation>=0.5 | correlation <= -0.5)
st <- strong_crl[,2]

names(ds4) <- str_replace_all(names(ds4), c(" "="_"))
names(ds4)[names(ds4) == "`MSZoning_C_(all)`"] <- "MSZoning_C_all" 
```

```{r 5. Data Partition}
set.seed(1)
spec = c(train = .6, test = .2, validate = .2)

g = sample(cut(
  seq(nrow(ds4)), 
  nrow(ds4)*cumsum(c(0,spec)),
  labels = names(spec)
))

res = split(ds4, g)
res$train
res$test
res$validate

```

```{r 6. 1st round training-validation}
mod1 <- lm(Sale_Price~.,data=res$train)
summary(mod1)
## 13 not defined because of singularities -> collinearity

new_obv <- res$validate %>% select(-c(Sale_Price))

pre_1 <- predict(mod1, newdata = new_obv, interval="confidence")

actual <- res$validate$Sale_Price
pred_result1 <- data.frame(pre_1)$fit

cor(actual, pred_result1)
rmse(actual, pred_result1)
mae(actual, pred_result1)
mean(min(actual, pred_result1)/max(actual, pred_result1))

#layout(matrix(c(1,2,3,4),2,2))
plot(mod1)
```

```{r 6. 2st round training-validation}
mod2 <- lm(as.formula(paste("Sale_Price", 
                            paste(st, collapse=" + "), 
                            sep=" ~ ")), data = res$train)
summary(mod2)
## 13 not defined because of singularities -> collinearity


pre_2 <- predict(mod2, newdata = new_obv, interval="confidence")

actual <- res$validate$Sale_Price
pred_result2 <- data.frame(pre_2)$fit

cor(actual, pred_result2)
rmse(actual, pred_result2)
mae(actual, pred_result2)
mean(min(actual, pred_result2)/max(actual, pred_result2))

#layout(matrix(c(1,2,3,4),2,2))
plot(mod2)
```


```{r 7. Model Comparison}
anova(mod1, mod2)
AIC(mod1, mod2)
BIC(mod1, mod2)
```

```{r 8. Testing}
test_obv <- res$test %>% select(-c(Sale_Price))

test_pre <- predict(mod2, newdata = test_obv, interval="confidence")

actual <- res$test$Sale_Price
pred_result <- data.frame(test_pre)$fit

cor(actual, pred_result)
rmse(actual, pred_result)
mae(actual, pred_result)
mean(min(actual, pred_result)/max(actual, pred_result))
```










